# Тематическое моделирование

### Задание
Классифицировать по тональности [отзывы на банки](https://drive.google.com/file/d/1i2_LP2SthhTF2jQQtGtI9iCsTYCKOsK7/view?usp=sharing) с сайта banki.ru.

Данные содержат непосредственно тексты отзывов, некоторую дополнительную информацию, а также оценку по шкале от 1 до 5.
Тексты хранятся в json-ах в массиве responses.

#### Часть 1. Анализ текстов
1. Посчитайте количество отзывов в разных городах и на разные банки.
2. Постройте гистограмы длин слов в символах и в словах.
3. Найдите 10 самых частых:
   - Слов.
   - Слов без стоп-слов.
   - Лемм.
   - Существительных.
     
4. Постройте кривые Ципфа и Хипса.
5. Ответьте на следующие вопросы:
   - Какое слово встречается чаще, "сотрудник" или "клиент"?
   - Сколько раз встречается слова "мошенничество" и "доверие"?
  
6. В поле "rating_grade" записана оценка отзыва по шкале от 1 до 5. Используйте меру $tf-idf$, для того, чтобы найти ключевые слова и биграмы для положительных отзывов (с оценкой 5) и отрицательных отзывов (с оценкой 1).

#### Часть 2. Тематическое моделирование
Постройте несколько тематических моделей коллекции документов с разным числом тем. Приведите примеры понятных (интерпретируемых) тем.

#### Часть 3. Классификация текстов
Сформулируем для простоты задачу бинарной классификации: будем классифицировать на два класса, то есть, различать резко отрицательные отзывы (с оценкой 1) и положительные отзывы (с оценкой 5).

1. Составьте обучающее и тестовое множество: выберите из всего набора данных N1 отзывов с оценкой 1 и N2 отзывов с оценкой 5 (значение N1 и N2 – на ваше усмотрение). Используйте sklearn.model_selection.train_test_split для разделения множества отобранных документов на обучающее и тестовое.
2. Используйте любой известный вам алгоритм классификации текстов для решения задачи и получите baseline. Сравните разные варианты векторизации текста: использование только униграм, пар или троек слов или с использованием символьных 
$n$-грам.
3. Сравните, как изменяется качество решения задачи при использовании скрытых тем в качестве признаков:
   - 1-ый вариант: $tf-idf$ преобразование (sklearn.feature_extraction.text.TfidfTransformer) и сингулярное разложение (оно же – латентый семантический анализ) (sklearn.decomposition.TruncatedSVD),
   - 2-ой вариант: тематические модели LDA (sklearn.decomposition.LatentDirichletAllocation). Используйте accuracy и F-measure для оценки качества классификации.

### Решение
[Файл с кодом и пояснениями](/Projects/08_Natural_language_processing/01_Thematic_modeling/Solution.ipynb)
